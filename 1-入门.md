# 入门

# LeNet网络结构详解与模型的搭建

## 原理

### 简单介绍LeNet

- LeNet分为卷积层块和全连接层块两个部分。
- 卷积层块⾥的基本单位是卷积层后接最⼤池化层
- 卷积层⽤来识别图像⾥的空间模式，如线条和物体局部，
- 最⼤池化层则⽤来降低卷积层对位置的敏感性。
- LeNet组成 卷积层、 下采样层、 卷积层、 下采样层、 三个全连接层

![20170906212851976](images/1-%E5%85%A5%E9%97%A8.assets/20170906212851976.jpeg)

### 详细介绍

**输入**：size为32×32像素大小的手写体字符图片（这些手写体包含从0-9的数字，即一共有10个类别的图片）,这些事单通道的灰度图
**输出**：分类结果（即0-9之间的一个数）

**LeNet-5的结构**如上图所示，网络**一共有7层（不包含输入层）**:<br>图中的**Convolutions**代表**卷积**、**Subsampling**代表**降采样**（也就是我们上面介绍的**池化**操作）、**Full connection**代表**全连接层**

**0、输入层 INPUT：**<br>输入二维图像，尺寸统一归一化为32×32 
**注意：本层不算LeNet-5的网络结构，传统上，不将输入层视为网络层次结构之一。**

**1、卷积层C1**  
**该层的作用为提取特征**
输入图片：32 * 32
卷积核大小：5 * 5  （整个lenet-5用到的卷积核尺寸均为5×5）
卷积核数量：6  （卷积核个数也就是输出的feature map 通道为6，即有6张feature map，每张feature map都是28×28，所以神经元数量为28×28×6）
输出feature map大小：28 * 28 （32-5+1）= 28
神经元数量：28 * 28 * 6
可训练参数：（5 * 5+1) * 6（每个滤波器5 * 5 = 25个unit参数和一个bias参数，一共6个滤波器）
连接数：（5 * 5+1）* 6 * 28 * 28 = 122304

**详细说明：**对输入图像进行第一次卷积运算（使用 6 个大小为 5 * 5 的卷积核），得到6个C1特征图（6个大小为28 * 28的 feature maps, 32-5+1=28）。我们再来看看需要多少个参数，卷积核的大小为5 * 5，总共就有6 *（5 * 5+1）=156个参数，其中+1是表示一个核有一个bias。对于卷积层C1，C1内的每个像素都与输入图像中的5 * 5个像素和1个bias有连接，所以总共有156*28*28=122304个连接（connection）。有122304个连接，但是我们只需要学习156个参数，主要是通过权值共享实现的

## 代码

### demo的流程

1. model.py ——定义LeNet网络模型
2. train.py ——加载数据集并训练，训练集计算loss，测试集计算accuracy，保存训练好的网络参数
3. predict.py——得到训练好的网络参数后，用自己找的图像进行分类测试



